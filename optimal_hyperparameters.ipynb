{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helpers import *\n",
    "from implementations import *\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(data_path):\n",
    "    try:\n",
    "        file_path = data_path + \"/x_train.csv\"\n",
    "\n",
    "        data = np.genfromtxt(file_path, delimiter=',', dtype=str, max_rows=1)\n",
    "        \n",
    "        # Extract the feature names\n",
    "        feature_names = data[1:]  \n",
    "        return feature_names.tolist()  \n",
    "    except FileNotFoundError:\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data('data/dataset/')\n",
    "feature_names = get_feature_names('data/dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lambda=1e-5\n",
    "best_gamma=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (328135, 321)\n",
      "x_test shape: (109379, 321)\n",
      "y_train shape: (328135,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing irrelevant columns and columns few answers\n",
    "\n",
    "COLUMNS_TO_REMOVE = [\n",
    "    \"_STATE\", \"FMONTH\", \"IDATE\", \"IMONTH\", \"IDAY\", \"IYEAR\", \"DISPCODE\", \"SEQNO\", \"_PSU\", \n",
    "    \"CTELENUM\", \"PVTRESD1\", \"COLGHOUS\", \"STATERES\", \"CELLFON3\", \"LADULT\", \n",
    "    \"NUMADULT\", \"NUMMEN\", \"NUMWOMEN\", \"CTELNUM1\", \"CELLFON2\", \"CADULT\", \n",
    "    \"PVTRESD2\", \"CCLGHOUS\", \"CSTATE\", \"LANDLINE\", \"HHADULT\", \"POORHLTH\", \n",
    "    \"ASTHNOW\", \"DIABAGE2\", \"RENTHOM1\", \"NUMHHOL2\", \"NUMPHON2\", \"CPDEMO1\", \n",
    "    \"INTERNET\", \"PREGNANT\", \"SMOKDAY2\", \"STOPSMK2\", \"LASTSMK2\", \"AVEDRNK2\", \n",
    "    \"DRNK3GE5\", \"MAXDRNKS\", \"LMTJOIN3\", \"ARTHDIS2\", \"ARTHSOCL\", \"JOINPAIN\", \n",
    "    \"SEATBELT\", \"FLUSHOT6\", \"FLSHTMY2\", \"IMFVPLAC\", \"PNEUVAC3\", \"HIVTSTD3\", \n",
    "    \"WHRTST10\", \"PDIABTST\", \"PREDIAB1\", \"INSULIN\", \"BLDSUGAR\", \"FEETCHK2\", \n",
    "    \"DOCTDIAB\", \"CHKHEMO3\", \"FEETCHK\", \"EYEEXAM\", \"DIABEYE\", \"DIABEDU\", \n",
    "    \"PAINACT2\", \"QLMENTL2\", \"QLSTRES2\", \"QLHLTH2\", \"CAREGIV1\", \"CRGVREL1\", \n",
    "    \"CRGVLNG1\", \"CRGVHRS1\", \"CRGVPRB1\", \"CRGVPERS\", \"CRGVHOUS\", \"CRGVMST2\", \n",
    "    \"CRGVEXPT\", \"VIDFCLT2\", \"VIREDIF3\", \"VIPRFVS2\", \"VINOCRE2\", \"VIEYEXM2\", \n",
    "    \"VIINSUR2\", \"VICTRCT4\", \"VIGLUMA2\", \"VIMACDG2\", \"CIMEMLOS\", \"CDHOUSE\", \n",
    "    \"CDASSIST\", \"CDHELP\", \"CDSOCIAL\", \"CDDISCUS\", \"WTCHSALT\", \"LONGWTCH\", \n",
    "    \"DRADVISE\", \"ASTHMAGE\", \"ASATTACK\", \"ASERVIST\", \"ASDRVIST\", \"ASRCHKUP\", \n",
    "    \"ASACTLIM\", \"ASYMPTOM\", \"ASNOSLEP\", \"ASTHMED3\", \"ASINHALR\", \"HAREHAB1\", \n",
    "    \"STREHAB1\", \"CVDASPRN\", \"ASPUNSAF\", \"RLIVPAIN\", \"RDUCHART\", \"RDUCSTRK\", \n",
    "    \"ARTTODAY\", \"ARTHWGT\", \"ARTHEXER\", \"ARTHEDU\", \"TETANUS\", \"HPVADVC2\", \n",
    "    \"HPVADSHT\", \"SHINGLE2\", \"HADMAM\", \"HOWLONG\", \"HADPAP2\", \"LASTPAP2\", \n",
    "    \"HPVTEST\", \"HPLSTTST\", \"HADHYST2\", \"PROFEXAM\", \"LENGEXAM\", \"BLDSTOOL\", \n",
    "    \"LSTBLDS3\", \"HADSIGM3\", \"HADSGCO1\", \"LASTSIG3\", \"PCPSAAD2\", \"PCPSADI1\", \n",
    "    \"PCPSARE1\", \"PSATEST1\", \"PSATIME\", \"PCPSARS1\", \"PCPSADE1\", \"PCDMDECN\", \n",
    "    \"SCNTMNY1\", \"SCNTMEL1\", \"SCNTPAID\", \"SCNTWRK1\", \"SCNTLPAD\", \"SCNTLWK1\", \n",
    "    \"SXORIENT\", \"TRNSGNDR\", \"RCSGENDR\", \"RCSRLTN2\", \"CASTHDX2\", \"CASTHNO2\", \n",
    "    \"EMTSUPRT\", \"LSATISFY\", \"ADPLEASR\", \"ADDOWN\", \"ADSLEEP\", \"ADENERGY\", \n",
    "    \"ADEAT1\", \"ADFAIL\", \"ADTHINK\", \"ADMOVE\", \"MISTMNT\", \"ADANXEV\", \"QSTVER\", \n",
    "    \"QSTLANG\", \"MSCODE\", \"_STSTR\", \"_STRWT\", \"_RAWRAKE\", \"_WT2RAKE\", \"_CHISPNC\", \n",
    "    \"_CRACE1\", \"_CPRACE\", \"_CLLCPWT\", \"_DUALUSE\", \"_DUALCOR\", \"_LLCPWT\", \n",
    "    \"_RFHLTH\", \"_HCVU651\", \"_RFHYPE5\", \"_CHOLCHK\", \"_RFCHOL\", \"_LTASTH1\", \n",
    "    \"_CASTHM1\", \"_ASTHMS1\", \"_DRDXAR1\", \"_PRACE1\", \"_MRACE1\", \"_HISPANC\", \n",
    "    \"_RACE\", \"_RACEG21\", \"_RACEGR3\", \"_RACE_G1\", \"_AGE65YR\",\n",
    "    \"_MISFRTN\", \"_MISVEGN\", \"_FRTRESP\", \"_VEGRESP\", \"_FRT16\", \"_VEG23\", \n",
    "    \"_FRUITEX\", \"_VEGETEX\", \"METVL11_\", \"METVL21_\", \"ACTIN11_\", \"ACTIN21_\", \n",
    "    \"PADUR1_\", \"PADUR2_\", \"PAFREQ1_\", \"PAFREQ2_\", \"_MINAC11\", \"_MINAC21\", \n",
    "    \"PAMISS1_\", \"PAMIN11_\", \"PAMIN21_\", \"PA1MIN_\", \"PAVIG11_\", \"PAVIG21_\", \n",
    "    \"PA1VIGM_\", \"_LMTACT1\", \"_LMTWRK1\", \"_LMTSCL1\", \"_RFSEAT2\", \"_RFSEAT3\", \n",
    "    \"_FLSHOT6\", \"_PNEUMO2\", \"_AIDTST3\", \"EXRACT11\", \"EXEROFT1\", \"EXERHMM1\", \n",
    "    \"EXRACT21\", \"EXEROFT2\", \"EXERHMM2\", \"PHYSHLTH\", \"MENTHLTH\", \"CHILDREN\", \n",
    "    \"WEIGHT2\", \"HEIGHT3\", \"ALCDAY5\", \"FRUITJU1\", \"FRUIT1\", \"FVBEANS\", \n",
    "    \"FVGREEN\", \"FVORANG\", \"VEGETAB1\", \"STRENGTH\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules to encode categorical data\n",
    "\n",
    "ENCODING_RULES = {\n",
    "    'GENHLTH': {'valid_range': (1, 5), 'invalid_values': {7, 9, np.nan}},\n",
    "    'HLTHPLN1': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'PERSDOC2': {'valid_range': (1, 3), 'invalid_values': {7, 9, np.nan}, 'no_value': 3},\n",
    "    'MEDCOST': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'CHECKUP1': {'valid_range': (1, 4), 'invalid_values': {7, 9, np.nan}, 'no_value': 8},\n",
    "    'BPHIGH4': {'valid_range': (1, 4), 'invalid_values': {7, 9, np.nan}, 'no_value': 3},\n",
    "    'BPMEDS': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'BLOODCHO': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'CHOLCHK': {'valid_range': (1, 4), 'invalid_values': {7, 9, np.nan}},\n",
    "    'TOLDHI2': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'CVDSTRK3': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'ASTHMA3': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'CHCSCNCR': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'CHCOCNCR': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'CHCCOPD1': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'HAVARTH3': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'ADDEPEV2': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'CHCKIDNY': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'DIABETE3': {'valid_range': (1, 4), 'invalid_values': {7, 9, np.nan}, 'no_value': 3},\n",
    "    'SEX': {'valid_range': (1, 2), 'invalid_values': {np.nan}},\n",
    "    'MARITAL': {'valid_range': (1, 6), 'invalid_values': {7, 9, np.nan}},\n",
    "    'EDUCA': {'valid_range': (1, 6), 'invalid_values': {7, 9, np.nan}},\n",
    "    'VETERAN3': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'EMPLOY1': {'valid_range': (1, 8), 'invalid_values': {9, np.nan}},\n",
    "    'INCOME2': {'valid_range': (1, 8), 'invalid_values': {77, 99, np.nan}},\n",
    "    'QLACTLM2': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'USEEQUIP': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'BLIND': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'DECIDE': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'DIFFWALK': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'DIFFDRES': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'DIFFALON': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'SMOKE100': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'USENOW3': {'valid_range': (1, 3), 'invalid_values': {7, 9, np.nan}, 'no_value': 3},\n",
    "    'EXERANY2': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    'HIVTST6': {'valid_range': (1, 2), 'invalid_values': {7, 9, np.nan}, 'no_value': 2},\n",
    "    '_AGEG5YR': {'valid_range': (1, 13), 'invalid_values': {14, np.nan}},\n",
    "    '_AGE_G': {'valid_range': (1, 6), 'invalid_values': {np.nan}},\n",
    "    '_BMI5CAT': {'valid_range': (1, 4), 'invalid_values': {np.nan}},\n",
    "    '_RFBMI5': {'valid_range': (1, 2), 'no_value': 1, 'invalid_values': {9, np.nan}},\n",
    "    '_CHLDCNT': {'valid_range': (1, 6), 'no_value': 1, 'invalid_values': {9, np.nan}},\n",
    "    '_EDUCAG': {'valid_range': (1, 4), 'no_value': 1, 'invalid_values': {9, np.nan}},\n",
    "    '_INCOMG': {'valid_range': (1, 5), 'invalid_values': {9, np.nan}},\n",
    "    '_SMOKER3': {'valid_range': (1, 4), 'no_value': 4, 'invalid_values': {9, np.nan}},\n",
    "    '_RFSMOK3': {'valid_range': (1, 2), 'no_value': 1, 'invalid_values': {9, np.nan}},\n",
    "    'DRNKANY5': {'valid_range': (1, 2), 'no_value': 2, 'invalid_values': {7, 9, np.nan}},\n",
    "    '_RFBING5': {'valid_range': (1, 2), 'no_value': 1, 'invalid_values': {9, np.nan}},\n",
    "    '_RFDRHV5': {'valid_range': (1, 2), 'no_value': 1, 'invalid_values': {9, np.nan}},\n",
    "    '_FRTLT1': {'valid_range': (1, 2), 'invalid_values': {9, np.nan}},\n",
    "    '_VEGLT1': {'valid_range': (1, 2), 'invalid_values': {9, np.nan}},\n",
    "    '_TOTINDA': {'valid_range': (1, 2), 'no_value': 2, 'invalid_values': {9, np.nan}},\n",
    "    '_PACAT1': {'valid_range': (1, 4), 'invalid_values': {9, np.nan}},\n",
    "    '_PAINDX1': {'valid_range': (1, 2), 'no_value': 2, 'invalid_values': {9, np.nan}},\n",
    "    '_PA150R2': {'valid_range': (1, 3), 'no_value': 3, 'invalid_values': {9, np.nan}},\n",
    "    '_PA300R2': {'valid_range': (1, 3), 'no_value': 3, 'invalid_values': {9, np.nan}},\n",
    "    '_PA30021': {'valid_range': (1, 2), 'invalid_values': {9, np.nan}},\n",
    "    '_PASTRNG': {'valid_range': (1, 2), 'no_value': 2, 'invalid_values': {9, np.nan}},\n",
    "    '_PAREC1': {'valid_range': (1, 4), 'no_value': 4, 'invalid_values': {9, np.nan}},\n",
    "    '_PASTAE1': {'valid_range': (1, 4), 'no_value': 4, 'invalid_values': {9, np.nan}},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rules for numerical data\n",
    "\n",
    "NUMERICAL_FEATURES_RULES = {\n",
    "    '_AGE80': {'invalid_values': {np.nan}},\n",
    "    'HTIN4': {'invalid_values': {np.nan}},\n",
    "    'HTM4': {'invalid_values': {np.nan}},\n",
    "    'WTKG3': {'invalid_values': {9999, np.nan}},\n",
    "    '_BMI5': {'invalid_values': {np.nan}},\n",
    "    'DROCDY3_': {'invalid_values': {900, np.nan}},\n",
    "    '_DRNKWEK': {'invalid_values': {99900, np.nan}},\n",
    "    'FTJUDA1_': {'invalid_values': {np.nan}},\n",
    "    'FRUTDA1_': {'invalid_values': {np.nan}},\n",
    "    'BEANDAY_': {'invalid_values': {np.nan}},\n",
    "    'GRENDAY_': {'invalid_values': {np.nan}},\n",
    "    'ORNGDAY_': {'invalid_values': {np.nan}},\n",
    "    'VEGEDA1_': {'invalid_values': {np.nan}},\n",
    "    '_FRUTSUM': {'invalid_values': {np.nan}},\n",
    "    '_VEGESUM': {'invalid_values': {np.nan}},\n",
    "    'MAXVO2_': {'invalid_values': {99900, np.nan}},\n",
    "    'FC60_': {'invalid_values': {99900, np.nan}},\n",
    "    'STRFREQ_': {'invalid_values': {99900, np.nan}},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns are accounted for.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks if every feature is either in 'COLUMNS_TO_REMOVE', 'ENCODING_RULES' or 'NUMERICAL_FEATURES_RULE'\n",
    "\n",
    "def check_all_columns_accounted_for(all_columns, columns_to_remove, encoding_rules, numerical_features_rules):\n",
    "    # Create a set of all the features that are either to be removed, encoded, or are numerical\n",
    "    all_accounted_columns = set(columns_to_remove) | set(encoding_rules.keys()) | set(numerical_features_rules.keys())\n",
    "    \n",
    "    # Create a set of all the columns from the dataset\n",
    "    all_columns_set = set(all_columns)\n",
    "    \n",
    "    # Find the set of columns that are not accounted for\n",
    "    unaccounted_columns = all_columns_set - all_accounted_columns\n",
    "    \n",
    "    if unaccounted_columns:\n",
    "        print(f\"The following columns are not accounted for: {', '.join(unaccounted_columns)}\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"All columns are accounted for.\")\n",
    "        return True\n",
    "\n",
    "check_all_columns_accounted_for(feature_names, COLUMNS_TO_REMOVE, ENCODING_RULES, NUMERICAL_FEATURES_RULES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(x_train, x_test, feature_names, nan_threshold=0.5):\n",
    "    # ------- Remove specified columns -------\n",
    "    # Find the indices of the columns to remove based on their names\n",
    "    indices_to_remove = []\n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        if feature_name in COLUMNS_TO_REMOVE:\n",
    "            indices_to_remove.append(i)\n",
    "\n",
    "    # Remove the specified columns from the training and test datasets\n",
    "    x_train = np.delete(x_train, indices_to_remove, axis=1)\n",
    "    x_test = np.delete(x_test, indices_to_remove, axis=1)\n",
    "\n",
    "    # Update the feature names list to exclude the removed columns\n",
    "    updated_feature_names = []\n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        if i not in indices_to_remove:\n",
    "            updated_feature_names.append(feature_name)\n",
    "\n",
    "    # ------- Remove columns with too many NaN values -------\n",
    "    # Calculate the percentage of NaN values in each column of the training data\n",
    "    nan_percentages = np.mean(np.isnan(x_train), axis=0)\n",
    "\n",
    "    # Identify columns with less than the threshold percentage of NaN values\n",
    "    valid_column_indices = nan_percentages < nan_threshold\n",
    "\n",
    "    # Keep only the valid columns in the training and test datasets\n",
    "    x_train = x_train[:, valid_column_indices]\n",
    "    x_test = x_test[:, valid_column_indices]\n",
    "\n",
    "    # Update the feature names list to include only those corresponding to valid columns\n",
    "    filtered_feature_names = []\n",
    "    for i, feature in enumerate(updated_feature_names):\n",
    "        if valid_column_indices[i]:\n",
    "            filtered_feature_names.append(feature)\n",
    "\n",
    "    return x_train, x_test, filtered_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(x_train, x_test, y_train, feature_names, invalid_percentage_threshold=0.5):\n",
    "    encoded_feature_names = []\n",
    "    new_x_train = []\n",
    "    new_x_test = []\n",
    "    train_missingness_matrix = []\n",
    "\n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        rules = ENCODING_RULES.get(feature_name)\n",
    "\n",
    "        if rules:\n",
    "            valid_range = rules.get('valid_range', (np.nanmin(x_train[:, i]), np.nanmax(x_train[:, i])))\n",
    "            invalid_values = rules.get('invalid_values', set())\n",
    "            no_value = rules.get('no_value')\n",
    "            \n",
    "            # Creates arrays to store the encoded features\n",
    "            encoded_train_column = []\n",
    "            encoded_test_column = []\n",
    "            \n",
    "            # Finding and storing missing data\n",
    "            invalid_non_nan = {x for x in invalid_values if not np.isnan(x)}\n",
    "            is_invalid_train = np.in1d(x_train[:, i], list(invalid_non_nan))\n",
    "            is_nan_train = np.isnan(x_train[:, i])\n",
    "            train_missingness = np.logical_or(is_invalid_train, is_nan_train).astype(int)\n",
    "\n",
    "            is_invalid_test = np.in1d(x_test[:, i], list(invalid_non_nan))\n",
    "            is_nan_test = np.isnan(x_test[:, i])\n",
    "            test_missingness = np.logical_or(is_invalid_test, is_nan_test).astype(int)\n",
    "            \n",
    "            train_missingness_matrix.append(train_missingness)  # Storing the missingness data\n",
    "            \n",
    "            # Updates the arrays storing the 'missing column' for the i-th feature \n",
    "            encoded_train_column.append(train_missingness)\n",
    "            encoded_test_column.append(test_missingness)\n",
    "            # Updates the new list of (encoded) features adding the '{feature_name}_missing' column\n",
    "            encoded_feature_names.append(f'{feature_name}_missing')\n",
    "            \n",
    "            # Changing values according to the rules\n",
    "            for val in range(valid_range[0], valid_range[1] + 1):\n",
    "                if val not in invalid_values and val != no_value:\n",
    "                    train_column = (x_train[:, i] == val).astype(int)\n",
    "                    test_column = (x_test[:, i] == val).astype(int)\n",
    "\n",
    "                    if no_value is not None:\n",
    "                        train_column[x_train[:, i] == no_value] = 0\n",
    "                        test_column[x_test[:, i] == no_value] = 0\n",
    "                    \n",
    "                    # Updates the arrays storing the val-column for the i-th feature \n",
    "                    encoded_train_column.append(train_column)\n",
    "                    encoded_test_column.append(test_column)\n",
    "                    # Updates the new list of (encoded) features adding the '{feature_name}_{val}' column\n",
    "                    encoded_feature_names.append(f'{feature_name}_{val}')\n",
    "            \n",
    "            # Combine the encoding of the i-th  feature with the ones already made for previous features\n",
    "            new_x_train.append(np.stack(encoded_train_column, axis=1))\n",
    "            new_x_test.append(np.stack(encoded_test_column, axis=1))\n",
    "        \n",
    "        # If there are no rules simply attaches the normal column\n",
    "        else:\n",
    "            new_x_train.append(x_train[:, i][:, np.newaxis])\n",
    "            new_x_test.append(x_test[:, i][:, np.newaxis])\n",
    "            encoded_feature_names.append(feature_name)\n",
    "\n",
    "    x_train_encoded = np.concatenate(new_x_train, axis=1)\n",
    "    x_test_encoded = np.concatenate(new_x_test, axis=1)\n",
    "\n",
    "    # Calculate the percentage of invalid values for each row\n",
    "    invalid_counts = np.sum(np.array(train_missingness_matrix).T, axis=1)\n",
    "    total_features = len(feature_names)\n",
    "    invalid_percentage = invalid_counts / total_features\n",
    "\n",
    "    # Removing rows with more than a certain percentage of invalid values\n",
    "    rows_to_remove = np.where(invalid_percentage > invalid_percentage_threshold)\n",
    "    x_train_encoded = np.delete(x_train_encoded, rows_to_remove, axis=0)\n",
    "    y_train = np.delete(y_train, rows_to_remove, axis=0)\n",
    "\n",
    "    return x_train_encoded, x_test_encoded, y_train, encoded_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_standardize_numerical_data(x_train, x_test, y_train, feature_names):\n",
    "    # Identify invalid values and replace them with NaN\n",
    "    for i, feature_name in enumerate(feature_names):\n",
    "        rules = NUMERICAL_FEATURES_RULES.get(feature_name)\n",
    "        if rules:\n",
    "            invalid_values = rules['invalid_values']\n",
    "            for val in invalid_values:\n",
    "                x_train[x_train[:, i] == val, i] = np.nan\n",
    "                x_test[x_test[:, i] == val, i] = np.nan\n",
    "\n",
    "    # Calculate the mean of valid values in the training set for each feature\n",
    "    valid_numerical_features_indices = [\n",
    "        i for i, feature_name in enumerate(feature_names) if feature_name in NUMERICAL_FEATURES_RULES\n",
    "    ]\n",
    "    x_train_numerical = x_train[:, valid_numerical_features_indices]\n",
    "    means = np.nanmean(x_train_numerical, axis=0)\n",
    "\n",
    "    # Replace NaNs with the calculated means\n",
    "    for i in range(x_train_numerical.shape[1]):\n",
    "        nan_indices_train = np.isnan(x_train_numerical[:, i])\n",
    "        x_train_numerical[nan_indices_train, i] = means[i]\n",
    "\n",
    "        nan_indices_test = np.isnan(x_test[:, valid_numerical_features_indices[i]])\n",
    "        x_test[nan_indices_test, valid_numerical_features_indices[i]] = means[i]\n",
    "\n",
    "    # Standardize the data (zero mean and unit variance)\n",
    "    stds = np.nanstd(x_train_numerical, axis=0, ddof=1)  # ddof=1 is used to compute sample standard deviation\n",
    "    stds[stds == 0] = 1  # Avoid division by zero\n",
    "    \n",
    "    x_train_numerical = (x_train_numerical - means) / stds\n",
    "    x_train[:, valid_numerical_features_indices] = x_train_numerical\n",
    "\n",
    "    # Apply the same transformation to the test set\n",
    "    x_test_numerical = x_test[:, valid_numerical_features_indices]\n",
    "    x_test_numerical = (x_test_numerical - means) / stds\n",
    "    x_test[:, valid_numerical_features_indices] = x_test_numerical\n",
    "\n",
    "    return x_train, x_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, feature_names = clean_dataset(x_train, x_test, feature_names, nan_threshold=0.5)\n",
    "x_train, x_test, y_train, feature_names = encode_data(x_train, x_test, y_train, feature_names, invalid_percentage_threshold=0.2)\n",
    "x_train, x_test, y_train = clean_and_standardize_numerical_data(x_train, x_test, y_train, feature_names)\n",
    "#x_train, y_train = remove_nan_rows(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert -1 labels to 0\n",
    "y_train[y_train == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (312052, 219)\n",
      "x_test shape: (109379, 219)\n",
      "y_train shape: (312052,)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the labels for the test data\n",
    "def predict_labels(w, data):\n",
    "    \"\"\"Generates class predictions given weights, and a test data matrix\"\"\"\n",
    "    y_pred = sigmoid(data.dot(w))\n",
    "    y_pred[np.where(y_pred <= 0.45)] = -1\n",
    "    y_pred[np.where(y_pred > 0.45)] = 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(x_test, y_test, w):\n",
    "    y_pred = np.array(predict_labels(w, x_test))\n",
    "    y_true = np.array(y_test)\n",
    "\n",
    "    # Calculating True Positives, False Positives, and False Negatives\n",
    "    TP = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    FP = np.sum((y_true == -1) & (y_pred == 1))\n",
    "    FN = np.sum((y_true == 1) & (y_pred == -1))\n",
    "\n",
    "    # Calculating Precision and Recall\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "\n",
    "    # Calculating F1 Score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Regularized logistic regression with optimal hyperparameters\n",
    "np.random.seed(13)\n",
    "initial_w = np.random.randn(x_train.shape[1]) * 0.01\n",
    "max_iters = 1000\n",
    "w, _ = reg_logistic_regression(y_train, x_train, best_lambda, initial_w, max_iters, best_gamma, threshold=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.0863482875060299\n"
     ]
    }
   ],
   "source": [
    "f1 = compute_f1(x_train, y_train, w)\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and save ouput in csv format for submission:\n",
    "OUTPUT_PATH = 'data/submission.csv'\n",
    "\n",
    "y_pred = predict_labels(w, x_test)\n",
    "\n",
    "#create_csv_submission(test_ids, y_pred, OUTPUT_PATH)\n",
    "create_csv_submission(test_ids, y_pred, OUTPUT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
